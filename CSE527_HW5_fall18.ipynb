{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random \n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as Func\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data():\n",
    "\n",
    "    path_feat = 'UCF101_release/vgg16_relu6/'\n",
    "    path_label = 'UCF101_release/annos/videos_labels_subsets.txt'\n",
    "    fp = open(path_label,'r')\n",
    "    samples = os.listdir(path_feat)\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    test_data= []\n",
    "    test_labels = []\n",
    "    for line in fp.readlines():\n",
    "        parts = line.strip().split('\\t')\n",
    "        if(int(parts[1])< 16 and not(int(parts[1])==1)):\n",
    "            mat_in = scipy.io.loadmat(path_feat+parts[0]+'.mat') \n",
    "            feat_in = mat_in['Feature']\n",
    "            if(parts[2]=='1'):\n",
    "                train_data.append(feat_in)\n",
    "                train_labels.append([int(parts[1])-1])\n",
    "            if(parts[2]=='2'):\n",
    "                test_data.append(feat_in)\n",
    "                test_labels.append([int(parts[1])-1])\n",
    "    train_data = np.array(train_data)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_data = np.array(test_data)\n",
    "    test_labels = np.array(test_labels)\n",
    "    bundle = list(zip(train_data, train_labels))\n",
    "    random.shuffle(bundle)\n",
    "    train_data, train_labels = zip(*bundle)\n",
    "    return train_data, train_labels, test_data, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, test_data, test_labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, feat_dim, hidden_dim1,hidden_dim2, cls_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim1 = hidden_dim1   # dimension of first hidden lstm layer\n",
    "        self.hidden_dim2 = hidden_dim2   # dimension of second hidden lstm layer\n",
    "        self.bn = nn.BatchNorm1d(25)     \n",
    "        self.lstm1 = nn.LSTM(feat_dim, hidden_dim1)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim1,hidden_dim2)\n",
    "        self.lin = nn.Linear(hidden_dim2, cls_size)\n",
    "        self.hidden1 = self.init_hidden1()\n",
    "        self.hidden2 = self.init_hidden2()\n",
    "        self.dp = nn.Dropout(p=0.2, inplace=False)\n",
    "\n",
    "\n",
    "    def init_hidden1(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim1),\n",
    "                torch.zeros(1, 1, self.hidden_dim1))\n",
    "    def init_hidden2(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_dim2),\n",
    "                torch.zeros(1, 1, self.hidden_dim2))\n",
    "\n",
    "    def forward(self, data):\n",
    "        lstm_out1, self.hidden1 = self.lstm1(data.view(25,1,-1), self.hidden1)\n",
    "        lstm_out2, self.hidden2 = self.lstm2(lstm_out1.view(25,1,-1), self.hidden2)\n",
    "        lin_out = self.lin(lstm_out2.view(25,-1))\n",
    "        cls_scores = F.log_softmax(lin_out, dim=1)\n",
    "        return cls_scores[-2:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = 4096\n",
    "hidden_dim1 = 512\n",
    "hidden_dim2 = 124\n",
    "cls_size = 15\n",
    "\n",
    "model = LSTMTagger(feat_dim, hidden_dim1,hidden_dim2, cls_size)\n",
    "loss_function = nn.NLLLoss()\n",
    "#loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for epoch in range(6):  \n",
    "    for data, labels in zip(train_data,train_labels):\n",
    "\n",
    "        #Step 1 : clear gardients and hidden states\n",
    "        model.zero_grad()\n",
    "        model.hidden1 = model.init_hidden1()\n",
    "        model.hidden2 = model.init_hidden2()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into tensors\n",
    "        data = torch.from_numpy(np.array(data))\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        labels = torch.from_numpy(np.array(labels))\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        cls_scores = model(data)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters \n",
    "        loss = loss_function(cls_scores, labels)\n",
    "       # i+= 1\n",
    "        #if(i%10 == 0):\n",
    "         #   print(i,loss[0])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy of my model =', 94)\n"
     ]
    }
   ],
   "source": [
    "  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "running_corrects = 0\n",
    "for data, labels in zip(test_data,test_labels):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.hidden1 = model.init_hidden1()\n",
    "        model.hidden2 = model.init_hidden2()\n",
    "\n",
    "        data = torch.from_numpy(np.array(data))\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        cls_scores = model(data)\n",
    "        labels = torch.from_numpy(np.array(labels))\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        _, preds = torch.max(cls_scores, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        #print(preds,labels)\n",
    "accuracy = running_corrects*100/test_data.shape[0]\n",
    "\n",
    "\n",
    "print(\"accuracy of my model =\",int(accuracy))\n",
    "#print(running_corrects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1341, 25, 4096)\n",
      "The accuracy of my dummy model is 95.23%\n"
     ]
    }
   ],
   "source": [
    "# Write your codes here\n",
    "train_data, train_labels, test_data, test_labels = load_data()\n",
    "train_data = np.array(train_data)\n",
    "from sklearn.svm import LinearSVC\n",
    "print(train_data.shape)\n",
    "train_svm = np.reshape(train_data,(train_data.shape[0],-1))\n",
    "train_labels = np.reshape(train_labels,(-1))\n",
    "test_labels = np.reshape(test_labels,(-1))\n",
    "\n",
    "test_svm = np.reshape(test_data,(test_data.shape[0],-1))\n",
    "clf3 = LinearSVC(random_state=0, tol=1e-5, max_iter = 10000, C= 0.2)\n",
    "clf3.fit(train_svm, train_labels)\n",
    "predictions3 = clf3.predict(test_svm)\n",
    "predictions3 = np.array(predictions3)\n",
    "test_labels = np.array(test_labels)    \n",
    "accuracy = sum(np.array(predictions3) == test_labels) / float(test_data.shape[0])\n",
    "\n",
    "print \"The accuracy of my svm model is {:.2f}%\".format(accuracy*100)\n",
    "\n",
    "\n",
    "#pred3, label3 = # train_and_test(..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
